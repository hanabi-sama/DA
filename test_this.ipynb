{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_this.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpYl7YWMKFmK",
        "outputId": "ca4443e4-1043-4d9a-8937-5cb43d8ad30c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir = \"/content/gdrive/MyDrive/DATN/dataset/test1\""
      ],
      "metadata": {
        "id": "ji7vEhusK5UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdir1 = '/content/gdrive/MyDrive/DATN/dataset/test'"
      ],
      "metadata": {
        "id": "0ptAHcSIVe-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdir2 = '/content/gdrive/MyDrive/DATN/dataset/test2'"
      ],
      "metadata": {
        "id": "HfIXR5yjXBnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = ['phuc','lenguyen','hamhuong','khanh','binhnguyen','luong','nhan']"
      ],
      "metadata": {
        "id": "rY0PGb1DOaOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "from tensorflow.keras.models import load_model\n",
        "root_dir = os.getcwd()\n",
        "model_path = os.path.join(root_dir,'/content/gdrive/MyDrive/DATN/models/facenet_keras.h5')\n",
        "facenet_model = load_model(model_path, compile=False)\n",
        "embeddings_model_file = os.path.join(root_dir,\"/content/gdrive/MyDrive/DATN/models/embeddings.pickle\")\n",
        "recognizer_model_file = os.path.join(root_dir,\"/content/gdrive/MyDrive/DATN/models/recognizer.pickle\")\n"
      ],
      "metadata": {
        "id": "SW0J8VrPO8_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_embeddings_and_labels():\n",
        "    data = pickle.loads(open(embeddings_model_file, \"rb\").read())\n",
        "    # encoding labels by names\n",
        "    label = LabelEncoder()\n",
        "    names = np.array(data[\"names\"])                       \n",
        "    labels = label.fit_transform(names)\n",
        "    # getting names\n",
        "    # getting embeddings\n",
        "    Embeddings = np.array(data[\"embeddings\"])\n",
        "    return [label,labels,Embeddings,names]"
      ],
      "metadata": {
        "id": "L7w0_nsRQNRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_pixels(imagearrays):\n",
        "\tface_pixels = np.array(imagearrays)\n",
        "\t# scale pixel values\n",
        "\tface_pixels = face_pixels.astype('float32')\n",
        "\t# standardize pixel values across channels (global)\n",
        "\tmean, std = face_pixels.mean(), face_pixels.std()\n",
        "\tface_pixels = (face_pixels - mean) / std\n",
        "\treturn face_pixels"
      ],
      "metadata": {
        "id": "XBgdSViBQOk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "[label,labels,Embeddings,names] = load_embeddings_and_labels()\n",
        "recognizer = pickle.loads(open('/content/gdrive/MyDrive/DATN/models/recognizer.pickle', \"rb\").read())"
      ],
      "metadata": {
        "id": "NECBwjNIQVrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "def check_faces(path,category_type):\n",
        "  predictor = {}\n",
        "  # path= os.path.join(path,category_type)\n",
        "  path= os.path.join(path)\n",
        "  for img in os.listdir(path):\n",
        "    try:\n",
        "      img = image.load_img(os.path.join(path,img),target_size=(160,160))\n",
        "      # img = image.img_to_array(img)\n",
        "      img = normalize_pixels(imagearrays=img)\n",
        "      img = np.expand_dims(img,axis=0)\n",
        "      # img = img / 255.0\n",
        "      embedding = facenet_model.predict(img)\n",
        "      embedding = embedding.reshape(1,-1)\n",
        "      preds = recognizer.predict_proba(embedding)[0]\n",
        "      p = np.argmax(preds)\n",
        "      proba = preds[p]\n",
        "      name = label.classes_[p]\n",
        "      if proba > 0.95:\n",
        "        if name == \"phuc\":\n",
        "          prediction_class = 0\n",
        "        elif name == \"lenguyen\":\n",
        "          prediction_class = 1\n",
        "        elif name == \"hamhuong\":\n",
        "          prediction_class = 2\n",
        "        elif name == \"khanh\":\n",
        "          prediction_class = 3\n",
        "        elif name == \"binhnguyen\":\n",
        "          prediction_class = 4\n",
        "        elif name == \"luong\":\n",
        "          prediction_class = 5\n",
        "        else:\n",
        "          prediction_class = 6\n",
        "      result = categories[prediction_class]\n",
        "      if result not in predictor:\n",
        "        predictor[result] = 1\n",
        "      else:\n",
        "        predictor[result] += 1\n",
        "    except Exception as e:\n",
        "      pass\n",
        "  return predictor"
      ],
      "metadata": {
        "id": "rULFIP6fOOSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_faces(test_dir,categories[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IvtJ5DNR83-",
        "outputId": "4911a925-ecd4-4e35-b29a-ebcc6100020d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'binhnguyen': 39,\n",
              " 'hamhuong': 42,\n",
              " 'khanh': 39,\n",
              " 'lenguyen': 43,\n",
              " 'luong': 41,\n",
              " 'nhan': 30,\n",
              " 'phuc': 52}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "def check_faces_spec(path,category_type):\n",
        "  predictor = {}\n",
        "  path= os.path.join(path,category_type)\n",
        "  # path= os.path.join(path)\n",
        "  for img in os.listdir(path):\n",
        "    try:\n",
        "      img = image.load_img(os.path.join(path,img),target_size=(160,160))\n",
        "      # img = image.img_to_array(img)\n",
        "      img = normalize_pixels(imagearrays=img)\n",
        "      img = np.expand_dims(img,axis=0)\n",
        "      # img = img / 255.0\n",
        "      embedding = facenet_model.predict(img)\n",
        "      embedding = embedding.reshape(1,-1)\n",
        "      preds = recognizer.predict_proba(embedding)[0]\n",
        "      p = np.argmax(preds)\n",
        "      proba = preds[p]\n",
        "      name = label.classes_[p]\n",
        "      if proba > 0.95:\n",
        "        if name == \"phuc\":\n",
        "          prediction_class = 0\n",
        "        elif name == \"lenguyen\":\n",
        "          prediction_class = 1\n",
        "        elif name == \"hamhuong\":\n",
        "          prediction_class = 2\n",
        "        elif name == \"khanh\":\n",
        "          prediction_class = 3\n",
        "        elif name == \"binhnguyen\":\n",
        "          prediction_class = 4\n",
        "        elif name == \"luong\":\n",
        "          prediction_class = 5\n",
        "        else:\n",
        "          prediction_class = 6\n",
        "      result = categories[prediction_class]\n",
        "      if result not in predictor:\n",
        "        predictor[result] = 1\n",
        "      else:\n",
        "        predictor[result] += 1\n",
        "    except Exception as e:\n",
        "      pass\n",
        "  return predictor"
      ],
      "metadata": {
        "id": "sJKgbaHiT8Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#binhnguyen : 41;\n",
        "# hamhuong : 40;\n",
        "# jkhanh : 41;\n",
        "# lenguyen : 41;\n",
        "# luong : 41;\n",
        "# phuc : 41;\n",
        "# nhan : 41;\n"
      ],
      "metadata": {
        "id": "L2XY9pCkTqMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_faces_spec(testdir2,categories[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-uH9PWiVXHj",
        "outputId": "52765a63-0079-4c9c-b750-68d096df7229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'phuc': 41}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_faces_spec(testdir2,categories[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjjTm1f4laEV",
        "outputId": "7c5ef3ee-4202-4ca9-cf39-5b8d6491120b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lenguyen': 41}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_faces_spec(testdir2,categories[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiWaqw0NlaR8",
        "outputId": "c587f234-6ba7-405a-c87d-ea4ff5d18163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hamhuong': 40}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_faces_spec(testdir2,categories[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1_9BO_Rladt",
        "outputId": "57773523-6c73-43da-e3c4-67732c27846c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'khanh': 33}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_faces_spec(testdir2,categories[4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lG_0bColanm",
        "outputId": "79a2dc43-5967-47e5-976c-78c7758f0a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'binhnguyen': 41}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_faces_spec(testdir2,categories[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5R4FFJDlc3G",
        "outputId": "b4d208c1-5045-460e-9f5e-7f885ec9a42f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'luong': 41}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_faces_spec(testdir2,categories[6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D12yHL8Nlc-x",
        "outputId": "38c2b266-6c62-4b09-c6cc-beb7d7cef1fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nhan': 38}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ]
}